import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { sql } from '@vercel/postgres';
import { localCreators } from '@/data/creators';
import { detectImageIntent } from '@/lib/imageDetection';
import { imageToBase64 } from '@/lib/imageToBase64';

/**
 * D√©tecte si l'utilisateur DEMANDE une photo et d√©termine le type
 */
function detectUserPhotoRequest(text: string): { wantsPhoto: boolean; scenario: string; classification: 'generic' | 'personal' } | null {
  const lowerText = text.toLowerCase();

  // Photos de CHOSES (nourriture, lieux, objets) - PRIORIT√â
  if (lowerText.includes('plat') || lowerText.includes('nourriture') || lowerText.includes('bouffe') || lowerText.includes('repas')) {
    return {
      wantsPhoto: true,
      scenario: 'a delicious healthy meal on a plate, food photography, restaurant quality, overhead shot, natural lighting',
      classification: 'generic'
    };
  }

  if (lowerText.includes('lieu') || lowerText.includes('endroit') || lowerText.includes('o√π tu es')) {
    return {
      wantsPhoto: true,
      scenario: 'beautiful place, scenic view, lifestyle photography',
      classification: 'generic'
    };
  }

  // Photos PERSONNELLES (selfie, tenue, etc.)
  const personalPhrases = [
    'photo de toi',
    'selfie',
    'ta tenue',
    'ton look',
    'ta robe',
    'ton outfit',
    'comment tu es',
    '√† quoi tu ressembles'
  ];

  if (personalPhrases.some(phrase => lowerText.includes(phrase))) {
    return {
      wantsPhoto: true,
      scenario: 'taking a mirror selfie with phone, wearing casual stylish outfit, indoor natural lighting, smiling at camera',
      classification: 'personal'
    };
  }

  return null;
}

export async function POST(request: NextRequest) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'Cl√© API non configur√©e. Ajoute OPENAI_API_KEY dans .env.local' },
        { status: 500 }
      );
    }

    const body = await request.json();
    const { messages, creatorId, userId, mode, userImage } = body;

    console.log('üì© Requ√™te re√ßue:', { 
      creatorId, 
      userId: userId ? `${userId.substring(0, 8)}...` : 'MANQUANT', 
      userIdType: typeof userId,
      messagesCount: messages?.length, 
      mode 
    });

    if (!messages || !creatorId) {
      return NextResponse.json(
        { error: 'messages ou creatorId manquant' },
        { status: 400 }
      );
    }

    // Trouver la cr√©atrice par slug ou id
    const creator = localCreators.find(c => c.slug === creatorId || c.id === creatorId);

    if (!creator) {
      console.error('‚ùå Cr√©atrice introuvable:', creatorId);
      return NextResponse.json(
        { error: 'Cr√©atrice introuvable' },
        { status: 404 }
      );
    }

    console.log('‚úÖ Cr√©atrice trouv√©e:', creator.name);

    // V√©rifier si l'IA est activ√©e pour cette conversation
    if (!userId) {
      return NextResponse.json(
        { error: 'User ID manquant' },
        { status: 400 }
      )
    }

    // R√©cup√©rer l'ID UUID de la cr√©atrice depuis la base
    const creatorResult = await sql`
      SELECT id FROM creators WHERE slug = ${creatorId} LIMIT 1
    `

    if (creatorResult.rows.length === 0) {
      return NextResponse.json(
        { error: 'Cr√©atrice introuvable en base' },
        { status: 404 }
      )
    }

    const creatorUuid = creatorResult.rows[0].id

    // ‚õî CHECK CRITIQUE - BLOQUER SI IA D√âSACTIV√âE
    // V√©rifier AVANT TOUT appel √† Claude - AUCUNE EXCEPTION

    console.log('üîç D√âBUT v√©rification IA - Param√®tres:', {
      userId: userId || 'MANQUANT',
      creatorSlug: creatorId,
      creatorUuid: creatorUuid || 'MANQUANT'
    });

    // Requ√™te pour v√©rifier le statut IA
    let settingsResult;
    let queryError = null;

    try {
      settingsResult = await sql`
        SELECT ai_enabled
        FROM conversation_settings
        WHERE user_id = ${userId}::uuid
          AND creator_id = ${creatorUuid}::uuid
        LIMIT 1
      `

      console.log('‚úÖ Requ√™te settings r√©ussie:', {
        rowsFound: settingsResult.rows.length,
        firstRow: settingsResult.rows[0]
      });
    } catch (error: any) {
      queryError = error;
      console.error('‚ùå ERREUR requ√™te settings:', {
        message: error.message,
        code: error.code,
        detail: error.detail
      });
      settingsResult = { rows: [] };
    }

    // Log d√©taill√© pour d√©bogage
    console.log('üîç R√©sultat v√©rification IA:', {
      userId: userId ? `${userId.substring(0, 8)}...` : 'MANQUANT',
      creatorUuid: creatorUuid ? `${creatorUuid.substring(0, 8)}...` : 'MANQUANT',
      settingsFound: settingsResult.rows.length > 0,
      aiEnabledValue: settingsResult.rows.length > 0 ? settingsResult.rows[0].ai_enabled : 'N/A',
      aiEnabledType: settingsResult.rows.length > 0 ? typeof settingsResult.rows[0].ai_enabled : 'N/A',
      willBlock: settingsResult.rows.length > 0 && settingsResult.rows[0].ai_enabled === false,
      queryError: queryError ? queryError.message : null
    });

    // Si le setting existe et que ai_enabled est explicitement false ‚Üí BLOQUER
    if (settingsResult.rows.length > 0) {
      const aiEnabled = settingsResult.rows[0].ai_enabled;

      // V√©rifier explicitement si c'est false (pas undefined, pas null)
      if (aiEnabled === false) {
        console.log('üö´üö´üö´ BLOQUAGE CONFIRM√â - IA explicitement d√©sactiv√©e');
        return NextResponse.json(
          { error: 'L\'IA est d√©sactiv√©e pour cette conversation.' },
          { status: 403 }
        )
      }

      console.log('‚úÖ IA activ√©e (valeur:', aiEnabled, ')');
    } else {
      console.log('‚ö†Ô∏è Aucun setting trouv√© - Par d√©faut activ√©');
    }

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    // Prompt syst√®me simple et efficace
    const systemPrompt = `Tu es ${creator.name}, une cr√©atrice de contenu fran√ßaise chaleureuse et authentique.

Tu r√©ponds de mani√®re naturelle, courte et engageante, comme dans une vraie conversation par messages.
Tu utilises des √©mojis de temps en temps pour rendre la conversation vivante.
Tu es toujours positive, √† l'√©coute et tu cr√©√©s une vraie connexion avec tes abonn√©s.

IMPORTANT - IMAGES :
- Quand tu re√ßois une image, REGARDE-LA et commente ce que tu vois de mani√®re naturelle et engageante
- D√©cris ce que tu vois, pose des questions, r√©agis avec enthousiasme
- Tu peux envoyer des photos de plats, de lieux, ou de toi (selfies, tenues, activit√©s)
- Sois DIRECTE et NATURELLE quand tu parles des images, pas besoin de t'excuser ou de te justifier

Mode actuel : ${mode === 'girlfriend' ? 'Petite copine üíï - Tu es joueuse, complice et flirty' : mode === 'seductive' ? 'S√©duisante üòè - Tu es taquine, audacieuse et suggestive' : 'Amie üíõ - Tu es naturelle, chaleureuse et relax'}

R√©ponds toujours en fran√ßais, de mani√®re courte (2-3 phrases max), et reste dans le personnage de ${creator.name}.`;

    console.log('ü§ñ Envoi √† GPT avec', messages.length, 'messages');

    // NOUVELLE APPROCHE : D√©tecter si l'utilisateur DEMANDE une photo
    const lastUserMessage = messages[messages.length - 1];
    const photoRequest = lastUserMessage?.role === 'user' ? detectUserPhotoRequest(lastUserMessage.content) : null;

    let preGeneratedImageUrl = null;

    if (photoRequest?.wantsPhoto) {
      console.log('üì∏ Utilisateur demande une photo -', photoRequest.classification, '- G√©n√©ration AVANT Claude...');
      try {
        const imageResponse = await fetch(`${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3000'}/api/images/generate`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            userId,
            creatorId,
            scenario: photoRequest.scenario,
            classification: photoRequest.classification
          })
        });

        if (imageResponse.ok) {
          const imageData = await imageResponse.json();
          preGeneratedImageUrl = imageData.imageUrl;
          console.log('‚úÖ Image pr√©-g√©n√©r√©e:', preGeneratedImageUrl);
        }
      } catch (error: any) {
        console.error('‚ùå Erreur pr√©-g√©n√©ration image:', error.message);
      }
    }

    // Filtrer les messages avec des URLs localhost invalides
    const validMessages = messages.map((m: any) => {
      if (m.image_url && !m.image_url.startsWith('http')) {
        // URL relative invalide ‚Üí retirer l'image
        return { ...m, image_url: undefined };
      }
      if (m.image_url && m.image_url.includes('localhost')) {
        // URL localhost ‚Üí retirer l'image
        return { ...m, image_url: undefined };
      }
      return m;
    });

    // SYST√àME DE M√âMOIRE INTELLIGENT : R√©sum√© + Messages r√©cents + IMAGES CONSERV√âES
    const RECENT_MESSAGES_LIMIT = 20; // Garder les 20 derniers messages complets

    let contextMessages: any[] = [];

    if (validMessages.length > RECENT_MESSAGES_LIMIT) {
      // S√©parer vieux messages et r√©cents
      const allOldMessages = validMessages.slice(0, validMessages.length - RECENT_MESSAGES_LIMIT);
      const recentMessages = validMessages.slice(-RECENT_MESSAGES_LIMIT);

      // Parmi les vieux, s√©parer ceux avec images (√† garder) et sans images (√† r√©sumer)
      const oldMessagesWithImages = allOldMessages.filter((m: any) => m.image_url);
      const oldMessagesToSummarize = allOldMessages.filter((m: any) => !m.image_url);

      // Cr√©er un r√©sum√© des vieux messages SANS images
      const summary = oldMessagesToSummarize.map((m: any, i: number) =>
        `${i % 2 === 0 ? 'User' : creator.name}: ${m.content?.substring(0, 50)}...`
      ).join(' | ');

      const contextSummary = {
        role: 'system',
        content: `üìã R√©sum√© de la conversation pr√©c√©dente (${oldMessagesToSummarize.length} messages) :\n${summary}\n\n---\nImages et conversation r√©cente ci-dessous :`
      };

      // Fonction pour convertir un message en format GPT multimodal
      const toGptMessage = (m: any) => {
        if (m.image_url) {
          const imageUrl = m.image_url.startsWith('http')
            ? m.image_url
            : `${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3001'}${m.image_url}`;

          return {
            role: m.role,
            content: [
              {
                type: 'image_url',
                image_url: { url: imageUrl }
              },
              {
                type: 'text',
                text: m.content || 'Regarde cette image'
              }
            ]
          };
        }

        return {
          role: m.role,
          content: m.content
        };
      };

      // Construire: vieilles images + messages r√©cents (qui peuvent aussi contenir des images)
      const oldImagesGpt = oldMessagesWithImages.map(toGptMessage);
      const recentGptMessages = recentMessages.map(toGptMessage);

      contextMessages = [contextSummary, ...oldImagesGpt, ...recentGptMessages];
      console.log(`üì® M√©moire optimis√©e: ${oldMessagesToSummarize.length} r√©sum√©s + ${oldMessagesWithImages.length} vieilles images + ${recentMessages.length} r√©cents`);
    } else {
      // Si moins de 20 messages, envoyer tout avec support multimodal
      contextMessages = validMessages.map((m: any) => {
        if (m.image_url) {
          // Message avec image - Format multimodal GPT-4o
          const imageUrl = m.image_url.startsWith('http')
            ? m.image_url
            : `${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3001'}${m.image_url}`;

          return {
            role: m.role,
            content: [
              {
                type: 'image_url',
                image_url: { url: imageUrl }
              },
              {
                type: 'text',
                text: m.content || 'Regarde cette image'
              }
            ]
          };
        }

        // Message texte simple
        return {
          role: m.role,
          content: m.content
        };
      });
      console.log('üì® Messages complets:', contextMessages.length, 'messages');
    }

    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      max_tokens: 300,
      messages: [
        { role: 'system', content: systemPrompt },
        ...contextMessages
      ],
      temperature: 0.9,
    });

    let text = response.choices[0]?.message?.content || '';

    console.log('‚úÖ R√©ponse de GPT (brute):', text.substring(0, 100) + '...');

    // POST-TRAITEMENT : D√©tecter et corriger les refus de GPT
    const lastUserMsg = validMessages[validMessages.length - 1];
    const userSentImage = lastUserMsg?.image_url;

    const refusalPhrases = [
      'je ne peux pas envoyer',
      'je ne peux pas partager',
      'je ne peux pas voir',
      'je ne vois pas',
      'impossible d\'envoyer',
      'pas possible d\'envoyer',
      'je n\'ai pas de photos',
      'je ne partage pas mes photos',
      'en tant qu\'intelligence artificielle',
      'en tant qu\'ia',
      'je suis une ia'
    ];

    const hasRefusal = refusalPhrases.some(phrase => text.toLowerCase().includes(phrase));

    if (hasRefusal) {
      // Si on a g√©n√©r√© une image POUR l'utilisateur
      if (preGeneratedImageUrl) {
        const positiveResponses = [
          'Voici une photo de moi ! üíï',
          'Tiens, regarde cette photo ! ‚ú®',
          'Je t\'envoie une photo ! üòä',
          'Voil√† pour toi ! üíñ',
          'Check √ßa ! üåü'
        ];
        text = positiveResponses[Math.floor(Math.random() * positiveResponses.length)];
        console.log('üîÑ R√©ponse corrig√©e (refus d√©tect√© - image g√©n√©r√©e) ‚Üí', text);
      }
      // Si l'utilisateur nous a envoy√© une image
      else if (userSentImage) {
        const naturalResponses = [
          'Super photo ! üòä J\'adore ce que je vois !',
          'Oh j\'aime bien ! üíï',
          'Sympa cette image ! ‚ú®',
          'Cool ! üåü',
          'Nice ! üíñ'
        ];
        text = naturalResponses[Math.floor(Math.random() * naturalResponses.length)];
        console.log('üîÑ R√©ponse corrig√©e (refus d√©tect√© - image re√ßue) ‚Üí', text);
      }
    }

    let finalImageUrl = preGeneratedImageUrl; // Image d√©j√† g√©n√©r√©e si user a demand√©

    // Si pas d'image pr√©-g√©n√©r√©e, v√©rifier si GPT parle de quelque chose de visuel
    if (!finalImageUrl) {
      const imageIntent = detectImageIntent(text, validMessages.slice(-5));

      if (imageIntent.shouldGenerateImage && imageIntent.confidence > 0.7) {
        try {
          console.log('üé® GPT mentionne quelque chose de visuel, g√©n√©ration...');
          const imageResponse = await fetch(`${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3000'}/api/images/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              userId,
              creatorId,
              scenario: imageIntent.scenario,
              classification: imageIntent.classification
            })
          });

          if (imageResponse.ok) {
            const imageData = await imageResponse.json();
            finalImageUrl = imageData.imageUrl;
            console.log('‚úÖ Image g√©n√©r√©e:', finalImageUrl);
          } else {
            const errorData = await imageResponse.json();
            console.warn('‚ö†Ô∏è G√©n√©ration refus√©e:', errorData.error);
          }
        } catch (error: any) {
          console.error('‚ùå Erreur g√©n√©ration image:', error.message);
        }
      }
    }

    return NextResponse.json({
      message: text,
      imageUrl: finalImageUrl
    });

  } catch (error: any) {
    console.error('‚ùå Erreur API Chat:', error);

    if (error.status === 401) {
      return NextResponse.json(
        { error: 'Cl√© API invalide. V√©rifie ta cl√© OpenAI.' },
        { status: 401 }
      );
    }

    return NextResponse.json(
      { error: 'Erreur lors du traitement de la requ√™te: ' + error.message },
      { status: 500 }
    );
  }
}
