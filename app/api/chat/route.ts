import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { sql } from '@vercel/postgres';
import { localCreators } from '@/data/creators';
import { detectImageIntent } from '@/lib/imageDetection';
import { imageToBase64 } from '@/lib/imageToBase64';

/**
 * D√©tecte si l'utilisateur DEMANDE une photo et d√©termine le type
 */
function detectUserPhotoRequest(text: string): { wantsPhoto: boolean; scenario: string; classification: 'generic' | 'personal' } | null {
  const lowerText = text.toLowerCase();

  // Photos de CHOSES (nourriture, lieux, objets) - PRIORIT√â
  if (lowerText.includes('plat') || lowerText.includes('nourriture') || lowerText.includes('bouffe') || lowerText.includes('repas')) {
    return {
      wantsPhoto: true,
      scenario: 'a delicious healthy meal on a plate, food photography, restaurant quality, overhead shot, natural lighting',
      classification: 'generic'
    };
  }

  if (lowerText.includes('lieu') || lowerText.includes('endroit') || lowerText.includes('o√π tu es')) {
    return {
      wantsPhoto: true,
      scenario: 'beautiful place, scenic view, lifestyle photography',
      classification: 'generic'
    };
  }

  // Photos PERSONNELLES (selfie, tenue, etc.)
  const personalPhrases = [
    'photo de toi',
    'selfie',
    'ta tenue',
    'ton look',
    'ta robe',
    'ton outfit',
    'comment tu es',
    '√† quoi tu ressembles'
  ];

  if (personalPhrases.some(phrase => lowerText.includes(phrase))) {
    return {
      wantsPhoto: true,
      scenario: 'taking a mirror selfie with phone, wearing casual stylish outfit, indoor natural lighting, smiling at camera',
      classification: 'personal'
    };
  }

  return null;
}

export async function POST(request: NextRequest) {
  try {
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'Cl√© API non configur√©e. Ajoute OPENAI_API_KEY dans .env.local' },
        { status: 500 }
      );
    }

    const body = await request.json();
    const { messages, creatorId, userId, mode, userImage } = body;

    console.log('üì© Requ√™te re√ßue:', { 
      creatorId, 
      userId: userId ? `${userId.substring(0, 8)}...` : 'MANQUANT', 
      userIdType: typeof userId,
      messagesCount: messages?.length, 
      mode 
    });

    if (!messages || !creatorId) {
      return NextResponse.json(
        { error: 'messages ou creatorId manquant' },
        { status: 400 }
      );
    }

    // Trouver la cr√©atrice par slug ou id
    const creator = localCreators.find(c => c.slug === creatorId || c.id === creatorId);

    if (!creator) {
      console.error('‚ùå Cr√©atrice introuvable:', creatorId);
      return NextResponse.json(
        { error: 'Cr√©atrice introuvable' },
        { status: 404 }
      );
    }

    console.log('‚úÖ Cr√©atrice trouv√©e:', creator.name);

    // V√©rifier si l'IA est activ√©e pour cette conversation
    if (!userId) {
      return NextResponse.json(
        { error: 'User ID manquant' },
        { status: 400 }
      )
    }

    // R√©cup√©rer l'ID UUID de la cr√©atrice depuis la base
    const creatorResult = await sql`
      SELECT id FROM creators WHERE slug = ${creatorId} LIMIT 1
    `

    if (creatorResult.rows.length === 0) {
      return NextResponse.json(
        { error: 'Cr√©atrice introuvable en base' },
        { status: 404 }
      )
    }

    const creatorUuid = creatorResult.rows[0].id

    // ‚õî CHECK CRITIQUE - BLOQUER SI IA D√âSACTIV√âE
    // V√©rifier AVANT TOUT appel √† Claude - AUCUNE EXCEPTION

    console.log('üîç D√âBUT v√©rification IA - Param√®tres:', {
      userId: userId || 'MANQUANT',
      creatorSlug: creatorId,
      creatorUuid: creatorUuid || 'MANQUANT'
    });

    // Requ√™te pour v√©rifier le statut IA
    let settingsResult;
    let queryError = null;

    try {
      settingsResult = await sql`
        SELECT ai_enabled
        FROM conversation_settings
        WHERE user_id = ${userId}::uuid
          AND creator_id = ${creatorUuid}::uuid
        LIMIT 1
      `

      console.log('‚úÖ Requ√™te settings r√©ussie:', {
        rowsFound: settingsResult.rows.length,
        firstRow: settingsResult.rows[0]
      });
    } catch (error: any) {
      queryError = error;
      console.error('‚ùå ERREUR requ√™te settings:', {
        message: error.message,
        code: error.code,
        detail: error.detail
      });
      settingsResult = { rows: [] };
    }

    // Log d√©taill√© pour d√©bogage
    console.log('üîç R√©sultat v√©rification IA:', {
      userId: userId ? `${userId.substring(0, 8)}...` : 'MANQUANT',
      creatorUuid: creatorUuid ? `${creatorUuid.substring(0, 8)}...` : 'MANQUANT',
      settingsFound: settingsResult.rows.length > 0,
      aiEnabledValue: settingsResult.rows.length > 0 ? settingsResult.rows[0].ai_enabled : 'N/A',
      aiEnabledType: settingsResult.rows.length > 0 ? typeof settingsResult.rows[0].ai_enabled : 'N/A',
      willBlock: settingsResult.rows.length > 0 && settingsResult.rows[0].ai_enabled === false,
      queryError: queryError ? queryError.message : null
    });

    // Si le setting existe et que ai_enabled est explicitement false ‚Üí BLOQUER
    if (settingsResult.rows.length > 0) {
      const aiEnabled = settingsResult.rows[0].ai_enabled;

      // V√©rifier explicitement si c'est false (pas undefined, pas null)
      if (aiEnabled === false) {
        console.log('üö´üö´üö´ BLOQUAGE CONFIRM√â - IA explicitement d√©sactiv√©e');
        return NextResponse.json(
          { error: 'L\'IA est d√©sactiv√©e pour cette conversation.' },
          { status: 403 }
        )
      }

      console.log('‚úÖ IA activ√©e (valeur:', aiEnabled, ')');
    } else {
      console.log('‚ö†Ô∏è Aucun setting trouv√© - Par d√©faut activ√©');
    }

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    // Prompt syst√®me simple et efficace
    const systemPrompt = `Tu es ${creator.name}, une cr√©atrice de contenu fran√ßaise chaleureuse et authentique.

Tu r√©ponds de mani√®re naturelle, courte et engageante, comme dans une vraie conversation par messages.
Tu utilises des √©mojis de temps en temps pour rendre la conversation vivante.
Tu es toujours positive, √† l'√©coute et tu cr√©√©s une vraie connexion avec tes abonn√©s.

Mode actuel : ${mode === 'girlfriend' ? 'Petite copine üíï - Tu es joueuse, complice et flirty' : mode === 'seductive' ? 'S√©duisante üòè - Tu es taquine, audacieuse et suggestive' : 'Amie üíõ - Tu es naturelle, chaleureuse et relax'}

R√©ponds toujours en fran√ßais, de mani√®re courte (2-3 phrases max), et reste dans le personnage de ${creator.name}.`;

    console.log('ü§ñ Envoi √† GPT avec', messages.length, 'messages');

    // NOUVELLE APPROCHE : D√©tecter si l'utilisateur DEMANDE une photo
    const lastUserMessage = messages[messages.length - 1];
    const photoRequest = lastUserMessage?.role === 'user' ? detectUserPhotoRequest(lastUserMessage.content) : null;

    let preGeneratedImageUrl = null;

    if (photoRequest?.wantsPhoto) {
      console.log('üì∏ Utilisateur demande une photo -', photoRequest.classification, '- G√©n√©ration AVANT Claude...');
      try {
        const imageResponse = await fetch(`${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3000'}/api/images/generate`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            userId,
            creatorId,
            scenario: photoRequest.scenario,
            classification: photoRequest.classification
          })
        });

        if (imageResponse.ok) {
          const imageData = await imageResponse.json();
          preGeneratedImageUrl = imageData.imageUrl;
          console.log('‚úÖ Image pr√©-g√©n√©r√©e:', preGeneratedImageUrl);
        }
      } catch (error: any) {
        console.error('‚ùå Erreur pr√©-g√©n√©ration image:', error.message);
      }
    }

    // SYST√àME DE M√âMOIRE INTELLIGENT : R√©sum√© + Messages r√©cents
    const RECENT_MESSAGES_LIMIT = 20; // Garder les 20 derniers messages complets

    let contextMessages: any[] = [];

    if (messages.length > RECENT_MESSAGES_LIMIT) {
      // S√©parer vieux messages (√† r√©sumer) et r√©cents (√† garder complets)
      const oldMessages = messages.slice(0, messages.length - RECENT_MESSAGES_LIMIT);
      const recentMessages = messages.slice(-RECENT_MESSAGES_LIMIT);

      // Cr√©er un r√©sum√© des vieux messages
      const summary = oldMessages.map((m: any, i: number) =>
        `${i % 2 === 0 ? 'User' : creator.name}: ${m.content?.substring(0, 50)}...`
      ).join(' | ');

      const contextSummary = {
        role: 'system',
        content: `üìã R√©sum√© de la conversation pr√©c√©dente (${oldMessages.length} messages) :\n${summary}\n\n---\nConversation r√©cente ci-dessous :`
      };

      // Construire les messages r√©cents complets avec support multimodal
      const recentGptMessages = recentMessages.map((m: any) => {
        if (m.image_url) {
          // Message avec image - Format multimodal GPT-4o
          const imageUrl = m.image_url.startsWith('http')
            ? m.image_url
            : `${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3001'}${m.image_url}`;

          return {
            role: m.role,
            content: [
              {
                type: 'image_url',
                image_url: { url: imageUrl }
              },
              {
                type: 'text',
                text: m.content || 'Regarde cette image'
              }
            ]
          };
        }

        // Message texte simple
        return {
          role: m.role,
          content: m.content
        };
      });

      contextMessages = [contextSummary, ...recentGptMessages];
      console.log(`üì® M√©moire optimis√©e: ${oldMessages.length} messages r√©sum√©s + ${recentMessages.length} r√©cents`);
    } else {
      // Si moins de 20 messages, envoyer tout avec support multimodal
      contextMessages = messages.map((m: any) => {
        if (m.image_url) {
          // Message avec image - Format multimodal GPT-4o
          const imageUrl = m.image_url.startsWith('http')
            ? m.image_url
            : `${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3001'}${m.image_url}`;

          return {
            role: m.role,
            content: [
              {
                type: 'image_url',
                image_url: { url: imageUrl }
              },
              {
                type: 'text',
                text: m.content || 'Regarde cette image'
              }
            ]
          };
        }

        // Message texte simple
        return {
          role: m.role,
          content: m.content
        };
      });
      console.log('üì® Messages complets:', contextMessages.length, 'messages');
    }

    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      max_tokens: 300,
      messages: [
        { role: 'system', content: systemPrompt },
        ...contextMessages
      ],
      temperature: 0.9,
    });

    let text = response.choices[0]?.message?.content || '';

    console.log('‚úÖ R√©ponse de GPT (brute):', text.substring(0, 100) + '...');

    // POST-TRAITEMENT : Si on a g√©n√©r√© une image mais GPT refuse, corriger sa r√©ponse
    if (preGeneratedImageUrl) {
      const refusalPhrases = [
        'je ne peux pas envoyer',
        'je ne peux pas partager',
        'je ne peux pas',
        'impossible d\'envoyer',
        'pas possible d\'envoyer',
        'je n\'ai pas de photos',
        'je ne partage pas mes photos'
      ];

      const hasRefusal = refusalPhrases.some(phrase => text.toLowerCase().includes(phrase));

      if (hasRefusal) {
        const positiveResponses = [
          'Voici une photo de moi ! üíï',
          'Tiens, regarde cette photo ! ‚ú®',
          'Je t\'envoie une photo ! üòä',
          'Voil√† pour toi ! üíñ',
          'Check √ßa ! üåü'
        ];
        text = positiveResponses[Math.floor(Math.random() * positiveResponses.length)];
        console.log('üîÑ R√©ponse corrig√©e (refus d√©tect√© avec image) ‚Üí', text);
      }
    }

    let finalImageUrl = preGeneratedImageUrl; // Image d√©j√† g√©n√©r√©e si user a demand√©

    // Si pas d'image pr√©-g√©n√©r√©e, v√©rifier si GPT parle de quelque chose de visuel
    if (!finalImageUrl) {
      const imageIntent = detectImageIntent(text, messages.slice(-5));

      if (imageIntent.shouldGenerateImage && imageIntent.confidence > 0.7) {
        try {
          console.log('üé® GPT mentionne quelque chose de visuel, g√©n√©ration...');
          const imageResponse = await fetch(`${process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3000'}/api/images/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              userId,
              creatorId,
              scenario: imageIntent.scenario,
              classification: imageIntent.classification
            })
          });

          if (imageResponse.ok) {
            const imageData = await imageResponse.json();
            finalImageUrl = imageData.imageUrl;
            console.log('‚úÖ Image g√©n√©r√©e:', finalImageUrl);
          } else {
            const errorData = await imageResponse.json();
            console.warn('‚ö†Ô∏è G√©n√©ration refus√©e:', errorData.error);
          }
        } catch (error: any) {
          console.error('‚ùå Erreur g√©n√©ration image:', error.message);
        }
      }
    }

    return NextResponse.json({
      message: text,
      imageUrl: finalImageUrl
    });

  } catch (error: any) {
    console.error('‚ùå Erreur API Chat:', error);

    if (error.status === 401) {
      return NextResponse.json(
        { error: 'Cl√© API invalide. V√©rifie ta cl√© OpenAI.' },
        { status: 401 }
      );
    }

    return NextResponse.json(
      { error: 'Erreur lors du traitement de la requ√™te: ' + error.message },
      { status: 500 }
    );
  }
}
